name = "FlashAttentionWrapper"
uuid = "4822a80a-c2d5-4bbd-b1da-f89b711347c8"
authors = ["Jun Tian <tianjun.cpp@gmail.com>"]
version = "0.1.0"

[deps]
BFloat16s = "ab4f0b2a-ad5b-11e8-123f-65d77653426b"
CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
ChainRules = "082447d4-558c-5d27-93f4-14fc19e9eca2"
ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
CondaPkg = "992eb4ea-22a4-4c89-a5bb-47a3300528ab"
DLPack = "53c2dc0f-f7d5-43fd-8906-6c0220547083"
Lux = "b2108857-7c20-44ae-9111-449ecde12c47"
LuxCore = "bb33d45b-7691-41d6-9220-0943567d0623"
NNlib = "872c559c-99b0-510c-b3b7-b6c96a88d5cd"
PythonCall = "6099a3de-0909-46bc-b1f4-468b9a2dfc0d"
Random = "9a3f8284-a2c9-5f02-9a11-845980a1fd5c"
Zygote = "e88e6eb3-aa80-5325-afca-941959d7151f"

[compat]
BFloat16s = "0.5.0"
CUDA = "5.5.2"
ChainRules = "1.72.1"
ChainRulesCore = "1.25.0"
CondaPkg = "0.2.24"
DLPack = "0.3.0"
Lux = "1.4.2"
LuxCore = "1.2.0"
NNlib = "0.9.26"
PythonCall = "0.9.23"
Random = "1.11.0"
Zygote = "0.6.41"

[extras]
CUDA_Runtime_jll = "76a88914-d11a-5bdc-97e0-2f5a05c973a2"
