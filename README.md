# FlashAttentionWrapper.jl

Just a simple wrapper for the [Flash Attention](https://github.com/Dao-AILab/flash-attention) operation.

## Installation

## Example

```
```

## TODO List

- [ ] Support FlexAttention?